sales_data <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) str(sales_data) sales_data
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017, main = "Dist ~ Speed")
boxplot(sales_data$Year_2007) boxplot(sales_data$Year_2017)
boxplot(sales_data$Year_2007)
boxplot(sales_data$Year_2017)
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017, main = "Dist ~ Speed")
scatter.smooth(x = sales_data$Year_2017, y = sales_data$Year_2007, main = "Dist ~ Speed")
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017, main = "Sales 2007 ~ Sales 2017")
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017, main = "Sales 2007 ~ Sales 2017", xlab = "Mililitres")
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017,     main = "Sales 2007 ~ Sales 2017", xlab = "2017", ylab = "2007")
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017,     main = "Sales 2007 ~ Sales 2017", xlab = "2007", ylab = "2017")
boxplot(sales_data$Year_2007)
boxplot(sales_data$Year_2017)
?boxplot
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017,     main = "Sales 2007 ~ Sales 2017", xlab = "2007", ylab = "2017")
library(e1071)
par(mfrow = c(1, 2)) # density plot for 'speed' plot(density(sales_data$Year_2007), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_data$Year_2007), 2)))
polygon(density(sales_data$Year_2007), col = "red")
# density plot for '2017' plot(density(sales_data$Year_2017), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_data$Year_2017), 2))) polygon(density(sales_data$Year_2017), col = "red")
cor(sales_data$2007, sales_data$2017)
cor(sales_data$Year_2007, sales_data$Year_2017)
linearMod <- lm(dist ~ speed, data = sales_data)
linearMod <- lm(Year_2007 ~ Year_2017, data = sales_data)
print(linearMod)
summary(linearMod)
# FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod)
# sample chooses a random sample # from 1:all records from sales_data, 80% of rows no_of_records <- sample(1:nrow(sales_data), 0.8 * nrow(sales_data)) # model training data training_data <- sales_data[no_of_records,] # test data testing_data <- sales_data[-no_of_records,]
# Build the model on training data lr_model <- lm(Year_2007 ~ Year_2017, data = training_data) # predict distance from testing data dist_predicted <- predict(lr_model, testing_data)
sales_predicted <- predict(lr_model, testing_data)
summary(lr_model)
actuals_preds <- data.frame(cbind(actuals = sales_data$Year_2017, predicted = sales_predicted)) head(actuals_preds)
actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
cvResults <- suppressWarnings(CVlm(data = sales_data, form.lm = Year_2007 ~ Year_2017, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_data, form.lm = Year_2007 ~ Year_2017, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
fit <- lm(Year_2007 ~ Year_2017, data = sales_data)
summary(fit)
cvResults <- suppressWarnings(CVlm(data = sales_data, form.lm = Year_2007 ~ Year_2017, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
cvResults <- suppressWarnings(CVlm(data = sales_data, form.lm = Year_2007 ~ Year_2017, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
linearMod <- lm(Year_2007 ~ Year_2017, data = sales_data) print(linearMod)
summary(lr_model)
summary(lr_model)
polynomial_regression_model <- lm(Year_2007 ~ Year_2017 + I(Year_2017 ^ 2) + I(Year_2017 ^ 3, data = training_data)polynomial_regression_model <- lm(Year_2007 ~ Year_2017 + I(Year_2017 ^ 2) + I(Year_2017 ^ 3), data = training_data)
polynomial_regression_model <- lm(Year_2007 ~ Year_2017 + I(Year_2017 ^ 2) + I(Year_2017 ^ 3), data = training_data)
summary(polynomial_regression_model)
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017,     main = "Sales 2007 ~ Sales 2017", xlab = "2007", ylab = "2017")
linearMod <- lm(Year_2007 ~ Year_2017, data = sales_data) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(Year_2007 ~ Year_2017 + I(Year_2017 ^ 2) + I(Year_2017 ^ 3), data = training_data) summary(polynomial_regression_model)
AIC(linearMod) BIC(linearMod)
AIC(polynomial_regression_model) BIC(polynomial_regression_model)
sum200 < sum(sales_data$Year_2000)
sales_data <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) str(sales_data) sales_data
sum200 < sum(sales_data$Year_2000)
sum200 <- sum(sales_data$Year_2000)
sum200
allsummed <- colSums(Filter(is.numeric, sales_data))
allsummed
sales_data <- allsummed
scatter.smooth(x = sales_data$Year_2007, y = sales_data$Year_2017,     main = "Sales 2007 ~ Sales 2017", xlab = "2007", ylab = "2017")
str(sales_data)
ma <- cbind(sales_data, "observation" = 1:nrow(sales_data)) ma
my_dataframe <- as.data.frame(allsummed)
ma <- cbind(sales_data, "observation" = 1:nrow(my_dataframe)) ma
ma <- cbind(sales_data, "observation" = 2000:nrow(my_dataframe)) ma
my_dataframe <- as.data.frame(allsummed)
my_dataframe
str(my_dataframe)
my_dataframe$year <- c(2000:2017)
my_dataframe
TotalSales <- colSums(Filter(is.numeric, sales_data)) TotalSales my_dataframe <- as.data.frame(TotalSales) my_dataframe$Year <- c(2000:2017) colnames(my_dataframe)[1] <- "newname2" my_dataframe
TotalSales <- colSums(Filter(is.numeric, sales_data)) TotalSales
TotalSales <- colSums(Filter(is.numeric, sales_data))
sales_data
TotalSales <- colSums(Filter(is.numeric, sales_data))
totalSales <- colSums(Filter(is.numeric, sales_data))
sales_data <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
str(sales_data) sales_data sum200 <- sum(sales_data$Year_2000) sum200 TotalSales <- colSums(Filter(is.numeric, sales_data)) TotalSales
my_dataframe <- as.data.frame(TotalSales) my_dataframe$Year <- c(2000:2017)
my_dataframe
scatter.smooth(x = sales_data$Year, y = sales_data$TotalSales,     main = "Year ~ Sales", xlab = "2007", ylab = "2017")
scatter.smooth(x = my_dataframe$Year, y = my_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "2007", ylab = "2017")
scatter.smooth(x = my_dataframe$Year, y = my_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = my_dataframe$Year, y = my_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
str(sales_dataframe)
sales_data <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) str(sales_data) sales_data sum200 <- sum(sales_data$Year_2000) sum200 TotalSales <- colSums(Filter(is.numeric, sales_data)) TotalSales sales_dataframe <- as.data.frame(TotalSales) sales_dataframe$Year <- c(2000:2017) colnames(sales_dataframe)[1] <- "newname2" sales_dataframe sales_data <- TotalSales str(sales_dataframe)
sales_data <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) str(sales_data) sales_data sum200 <- sum(sales_data$Year_2000) sum200 TotalSales <- colSums(Filter(is.numeric, sales_data)) TotalSales sales_dataframe <- as.data.frame(TotalSales) sales_dataframe$Year <- c(2000:2017) sales_dataframe sales_data <- TotalSales str(sales_dataframe)
boxplot(sales_data$Year) boxplot(sales_data$TotalSales)
boxplot(sales_dataframe$Year)
boxplot(sales_dataframe$Year)
boxplot(sales_dataframe$TotalSales)
sales_dataframe <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) str(sales_dataframe) sales_dataframe
sales_dataframe <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) TotalSales <- colSums(Filter(is.numeric, sales_dataframe)) TotalSales sales_dataframe <- as.data.frame(TotalSales) sales_dataframe$Year <- c(2000:2017) sales_dataframe sales_dataframe <- TotalSales str(sales_dataframe) scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales_dataframe
            , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
sales_dataframe <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
TotalSales <- colSums(Filter(is.numeric, sales_dataframe)) TotalSales
sales_dataframe <- as.data.frame(TotalSales) sales_dataframe$Year <- c(2000:2017) sales_dataframe
str(sales_dataframe)
##################################### # Read in the sales data, and create the data frame ##################################### sales_dataframe <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) TotalSales <- colSums(Filter(is.numeric, sales_dataframe)) TotalSales sales_dataframe <- as.data.frame(TotalSales) sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe)
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$TotalSales)
plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2)))
plot(density(sales_dataframe$TotalSales), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
plot(density(sales_dataframe$TotalSales), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
sales_dataframe
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
# build linear regression model on full data linearMod <- lm(Year ~ TotalSales, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(Year ~ TotalSales + I(TotalSales ^ 2) + I(TotalSales ^ 3), data = training_data) summary(polynomial_regression_model)
AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(Year ~ TotalSales, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data)
# make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(Year ~ TotalSales, data = training_data) summary(lr_model)
sales_predicted <- predict(lr_model, testing_data)
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted))
nrow(sales_dataframe)
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.5 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(Year ~ TotalSales, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data)
sales_predicted <- predict(lr_model, testing_data)
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
sales_dataframe <- sales_dataframe[-c(1, 2, 3),]
nrow(sales_dataframe)
sales_dataframe
sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,]
lr_model <- lm(Year ~ TotalSales, data = training_data) summary(lr_model)
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales_predicted
##################################### sales_dataframe <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
# Create Total Sales Vector TotalSales <- colSums(Filter(is.numeric, sales_dataframe)) sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe)
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales_dataframe
            , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
TotalSales <- colSums(Filter(is.numeric, sales)) sales_dataframe <- as.data.frame(TotalSales)
sales_dataframe$Year <- c(2000:2017) sales_dataframe
sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales
TotalSales <- c(colSums(Filter(is.numeric, sales)))
TotalSales
str(TotalSales)
TotalSales <- colSums(Filter(is.numeric, sales))
df <- as.data.frame(TotalSales)
df
df$TotalSales
sales_dataframe <- as.data.frame(df$TotalSales)
# Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe)
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales_dataframe
TotalSales <- df$TotalSales
sales_dataframe <- as.data.frame(TotalSales)
# Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
# BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
linearMod <- lm(Year ~ TotalSales, data = sales_dataframe) print(linearMod) summary(linearMod)
polynomial_regression_model <- lm(Year ~ TotalSales + I(TotalSales ^ 2) + I(TotalSales ^ 3), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
# Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,]
lr_model <- lm(Year ~ TotalSales, data = training_data) summary(lr_model)
sales_predicted <- predict(lr_model, testing_data) sales_predicted
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
correlation_accuracy
correlation_accuracy
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
summary(polynomial_regression_model)
linearMod <- lm(TotalSales ~ Year, data = sales_dataframe)
print(linearMod) summary(linearMod)
linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model)
summary(polynomial_regression_model)
AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model)
sales_predicted <- predict(lr_model, testing_data) sales_predicted
sales_predicted <- predict(lr_model, testing_data) sales_predicted
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
sales_dataframe
sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe
sales_dataframe
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector #TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales <- colSums(Filter(is.numeric, sales)) str(TotalSales) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe)
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
#There are no outliers install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2))
plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red")
plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model)
AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(linearMod) BIC(linearMod)
sales_dataframe
sales_dataframe <- sales_dataframe[-c(1, 2, 3),]
sales_dataframe
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model)
sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
actuals_preds
sales_predicted
sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " "))
sales
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) sales # Create Total Sales Vector #TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales <- colSums(Filter(is.numeric, sales)) str(TotalSales) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
# Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales) #There are no outliers install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales) #There are no outliers install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
#install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,]
# Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
# Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model)
sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
 # predict sales from testing data sales_predicted <- predict(linearMod, testing_data) sales_predicted
# make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
mape
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model)
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales) #There are no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
TotalSales
TotalSales/1000
TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales
TotalSales <- colSums(Filter(is.numeric, sales)) / 1000 TotalSales
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) / 1000 TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales) #There are no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) #fit3 <- lm(weight ~ height + I(height ^ 2) + I(height ^ 3), data = women) # predict sales from testing data sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
sales_dataframe
# density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
actuals_preds
sales_dataframe
testing_data
training_data
sales_predicted <- predict(polynomial_regression_model, testing_data) sales_predicted
actuals_preds
testing_data
sales_predicted <- predict(lr_model, testing_data) sales_predicted
# make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales) #There are no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red") # calculate correlation between Year and Total Sales cor(sales_dataframe$Year, sales_dataframe$TotalSales) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe) # Remove first 3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[-c(1, 2, 3),] sales_dataframe # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) summary(lr_model) testing_data training_data # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
summary(fit)
mape
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = Year ~ TotalSales, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals.")); fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
? CVlm
?CVlm
?lm
training_data
nrow(sales_dataframe)
testing_data
training_data
?lm
lr_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(lr_model)
# predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model)
# predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) testing_data training_data # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
acf_res <- acf(sales_dataframe) # autocorrelation
# partial autocorrelation pacf_res <- pacf(sales_dataframe)
str(AirPassengers)
acf_res <- acf(sales_dataframe$TotalSales) # autocorrelation
pacf_res <- pacf(sales_dataframe$TotalSales)
pacf_res <- pacf(sales_dataframe$TotalSales)
plot(sales_dataframe)
plot(sales_dataframe)
plot(sales_dataframe, x = sales_dataframe$TotalSales, y = sales_dataframe$Year)
plot(sales_dataframe$TotalSales)
plot(Nile)
str(Nile)
ts_sales <- ts(sales_dataframe$TotalSales, start = c(2003), end = c(2017), frequency = 1)
plot(ts_sales)
# ARIMA sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe acf_res <- acf(sales_dataframe$TotalSales) # autocorrelation # partial autocorrelation pacf_res <- pacf(sales_dataframe$TotalSales) plot(sales_dataframe$TotalSales) ts_sales <- ts(sales_dataframe$TotalSales, start = c(2003), end = c(2017), frequency = 1) plot(ts_sales)
# ARIMA sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe acf_res <- acf(sales_dataframe$TotalSales) # autocorrelation # partial autocorrelation pacf_res <- pacf(sales_dataframe$TotalSales) plot(sales_dataframe$TotalSales) ts_sales <- ts(sales_dataframe$TotalSales, start = c(2000), end = c(2017), frequency = 1) plot(ts_sales)
decomposed_result <- decompose(ts_sales, type = "mult") plot(decomposed_result)
decomposed_result <- decompose(ts_sales, type = "periodic") plot(decomposed_result)
decomposed_result <- decompose(ts_sales, type = "periodic")
decomposed_result <- decompose(ts_sales, type = "additive")
ts_sales <- ts(sales_dataframe, start = c(2000), end = c(2017), frequency = 1) plot(ts_sales)
decomposed_result <- decompose(ts_sales, type = "additive") plot(decomposed_result)
decomposed_result <- decompose(ts_sales, type = "additive")
ts_sales
ts_sales <- ts(sales_dataframe, start = c(2000), end = c(2017), frequency = 1)
ts_sales
ts_sales <- ts(sales_dataframe, start = c(2000), end = c(2017), frequency = 1) plot(ts_sales)
pacf_res <- pacf(sales_dataframe$TotalSales) plot(sales_dataframe$TotalSales)
plot(sales_dataframe$TotalSales)
plot(ts_sales)
ts_sales <- ts(sales_dataframe$TotalSales, start = c(2000), end = c(2017), frequency = 1) plot(ts_sales)
sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe ts_sales <- ts(sales_dataframe$TotalSales, start = c(2000), end = c(2017), frequency = 1) plot(ts_sales)
ndiffs(ts_sales)
library(forecast) library(tseries)
ndiffs(ts_sales)
ndiffs(ts_sales)
d_sales <- diff(ts_sales) # Plot the differenced time series plot(d_sales)
ndiffs(d_sales)
adf.test(d_sales)
Acf(d_sales) # partial autocorrelation plot Pacf(d_sales)
fit <- Arima(ts_sales, order = c(0, 1, 1)) fit # Accuracy measures accuracy(fit)
qqnorm(fit$residuals) qqline(fit$residuals)
qqnorm(fit$residuals)
qqline(fit$residuals)
Box.test(fit$residuals, type = "Ljung-Box")
forecast(fit, 3)
forecast(fit, 3)
actuals_preds
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$Year)
sales_dataframe
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") par(new = TRUE) # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$Year)
boxplot(sales_dataframe$TotalSales)
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers boxplot(sales_dataframe$Year) boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$TotalSales)
boxplot(sales_dataframe$Year)
boxplot(sales_dataframe$TotalSales)
##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plote the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
boxplot(sales_dataframe$TotalSales)
# density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
 #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "blue")
# density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red")
# density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: 2017", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red")
# density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Saleses", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
# density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2)))
# divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "red")
par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "blue")
cor(sales_dataframe$Year, sales_dataframe$TotalSales)
# calculate correlation between Year and Total Sales correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales) print(correlation)
correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales)
# calculate correlation between Year and Total Sales correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales) print(correlation)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_regression_model)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe)
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plot the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers in the sales boxplot(sales_dataframe$TotalSales)  #There ar  e no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "blue") # calculate correlation between Year and Total Sales correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales) print(correlation) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) nrow(sales_dataframe)
sales_dataframe
sales_dataframe
sales_dataframe <- sample(nrow(sales_dataframe), 15)
sales_dataframe
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) # Plot the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers in the sales boxplot(sales_dataframe$TotalSales)  #There ar  e no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "blue") # calculate correlation between Year and Total Sales correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales) print(correlation) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) print(linearMod) summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
sales_dataframe
sales_dataframe_sample <- sales_dataframe[sample(nrow(sales_dataframe), 15),]
sales_dataframe
sales_dataframe_sample
nrow(sales_dataframe_sample)
sales_dataframe <- sales_dataframe[sample(nrow(sales_dataframe), 15),]
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) testing_data training_data # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
correlation_accuracy <- cor(actuals_preds) correlation_accuracy
library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
# sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) # model training data training_data <- sales_dataframe[no_of_records,] # test data testing_data <- sales_dataframe[-no_of_records,] # Build the model on training data lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
no_of_records <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe))
print(no_of_records)
polynomial_regression_model
summary(polynomial_regression_model)
lr_model <- lm(TotalSales ~ Year, data = training_data) #lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
lr_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = training_data)
sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
lr_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(lr_model) # predict sales from testing data sales_predicted <- predict(lr_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) summary(polynomial_regression_model) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
summary(linearMod) polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) #summary(polynomial_regression_model) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2) + I(Year ^ 3), data = sales_dataframe)
AIC(polynomial_regression_model) BIC(polynomial_regression_model AIC(polynomial_regression_model) BIC(polynomial_regression_model)
AIC(polynomial_regression_model) BIC(polynomial_regression_model)
summary(linearMod)
summary(polynomial_regression_model)
polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) summary(polynomial_regression_model)
# build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) # build linear polynomial model on full data polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) # FOR MODEL COMPARISON, THE MODEL WITH THE LOWEST AIC AND BIC SCORE IS PREFERRED # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model)
summary(polynomial_r_model)
# Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
# Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
# Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
# Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
# Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model)
summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = sales_dataframe$TotalSales, predicted = sales_predicted)) actuals_preds
sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted
sales_predicted testing_data
TotalSales <- c(0,0,0) futureSales <- as.data.frame(TotalSales) futureSales$Year <- c(2018:2020)
futuresales_predicted <- predict(polynomial_r_model, futureSales)
futuresales_predicted
# make actuals_predicteds dataframe. actuals_preds <- data.frame(cbind(actuals = testing_data$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
actuals_preds
# compare the actual sales with the predicated sales actuals_preds <- data.frame(cbind(actuals = testing_data$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
sales_dataframe
new <- rbind(sales_dataframe, futuresales_predicted)
new
futuresales_predicted
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe)
original_sales_dataframe <- sales_dataframe
original_sales_dataframe
rbind(original_sales_dataframe,predicted_sales_dataframe)
TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020)
rbind(original_sales_dataframe,predicted_sales_dataframe)
original_sales_dataframe
originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) originalandpredicted_sales
scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape
TotalSales <- c(0,0,0) futureSales <- as.data.frame(TotalSales) futureSales$Year <- c(2018:2020) futuresales_predicted <- predict(polynomial_r_model, futureSales) futuresales_predicted
TotalSales <- c(0,0,0) futureSales <- as.data.frame(TotalSales) futureSales$Year <- c(2018:2020) futuresales_predicted <- predict(polynomial_r_model, futureSales) futuresales_predicted
# Create a new predicted sales dataframe # and append it to the original dataframe # so that it can be plotted TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020) originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
# Create a new predicted sales dataframe # and append it to the original dataframe # so that it can be plotted TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020) originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "2000 to 2017 Year ~ Sales. 2018 to 2020 Predictions.", xlab = "Year", ylab = "Sales (Million)")
scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "2000 to 2017 Year ~ Sales. 2018 to 2020 Predictions.", xlab = "Year", ylab = "Sales (Million)")
# Create a new predicted sales dataframe # and append it to the original dataframe # so that it can be plotted TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020) originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "2000 to 2017 Year ~ Sales. 2018 to 2020 Predictions.",     xlab = "Year", ylab = "Sales (Million)")
# Create a new predicted sales dataframe # and append it to the original dataframe # so that it can be plotted TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020) originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "2000 to 2017 Year ~ Sales. 2018 to 2020 Predictions.",     xlab = "Year", ylab = "Sales (Million)")
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values while bigger ones are actuals."));
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values. Larger symbols are actuals."))
#K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values. Larger symbols are actuals."))
fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
 ##################################### # Read in the sales data, and create the data frame ##################################### sales <- read.csv(header = TRUE, "SalesPerBusinessSector2000to2017.csv"             , stringsAsFactors = FALSE, na.strings = c("", "NA", " ")) # Create Total Sales Vector from all numeric columns TotalSales <- colSums(Filter(is.numeric, sales)) TotalSales df <- as.data.frame(TotalSales) TotalSales <- df$TotalSales sales_dataframe <- as.data.frame(TotalSales) # Create Year Vector sales_dataframe$Year <- c(2000:2017) sales_dataframe str(sales_dataframe) original_sales_dataframe <- sales_dataframe original_sales_dataframe # Plot the total sales from 2000 to 2017 scatter.smooth(x = sales_dataframe$Year, y = sales_dataframe$TotalSales,     main = "Year ~ Sales", xlab = "Year", ylab = "Sales (Million)") # BoxPlot - Check for outliers in the sales boxplot(sales_dataframe$TotalSales)  #There ar e no outliers #install.packages("e1071") library(e1071) # divide graph area in 2 columns par(mfrow = c(1, 2)) # density plot for '2007' plot(density(sales_dataframe$Year), main = "Density Plot: Years", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$Year), 2))) polygon(density(sales_dataframe$Year), col = "red") # density plot for Total Sales plot(density(sales_dataframe$TotalSales), main = "Density Plot: Total Sales", ylab = "Frequency",     sub = paste("Skewness:", round(e1071::skewness(sales_dataframe$TotalSales), 2))) polygon(density(sales_dataframe$TotalSales), col = "blue") # calculate correlation between Year and Total Sales correlation <- cor(sales_dataframe$Year, sales_dataframe$TotalSales) print(correlation) # build linear regression model on full data linearMod <- lm(TotalSales ~ Year, data = sales_dataframe) # build polynomial linear model on full data polynomial_regression_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = sales_dataframe) # Evaluates goodness of fit fo models  AIC(linearMod) BIC(linearMod) AIC(polynomial_regression_model) BIC(polynomial_regression_model) # Remove a random  3 rows because we currently have 18 # and we want 15 rows for an 80%-20% split (i.e. 12 - 3) sales_dataframe <- sales_dataframe[sample(nrow(sales_dataframe), 15),] # sample chooses a random sample # from 1:all records from sales_dataframe, 80% of rows records_for_training <- sample(1:nrow(sales_dataframe), 0.8 * nrow(sales_dataframe)) print(records_for_training) # model training data training_data <- sales_dataframe[records_for_training,] # test data testing_data <- sales_dataframe[-records_for_training,] # Build the model on training data polynomial_r_model <- lm(TotalSales ~ Year + I(Year ^ 2), data = training_data) summary(polynomial_r_model) # predict sales from testing data sales_predicted <- predict(polynomial_r_model, testing_data) sales_predicted # compare the actual sales with the predicated sales actuals_preds <- data.frame(cbind(actuals = testing_data$TotalSales, predicted = sales_predicted)) actuals_preds #Calculate the co-relation accuracy correlation_accuracy <- cor(actuals_preds) correlation_accuracy # Predict for next three years TotalSales <- c(0,0,0) futureSales <- as.data.frame(TotalSales) futureSales$Year <- c(2018:2020) futuresales_predicted <- predict(polynomial_r_model, futureSales) futuresales_predicted # Create a new predicted sales dataframe # and append it to the original dataframe # so that it can be plotted TotalSales <- futuresales_predicted predicted_sales_dataframe <- as.data.frame(TotalSales) predicted_sales_dataframe$Year <- c(2018:2020) originalandpredicted_sales <- rbind(original_sales_dataframe, predicted_sales_dataframe) scatter.smooth(x = originalandpredicted_sales$Year, y = originalandpredicted_sales$TotalSales,     main = "2000 to 2017 Year ~ Sales. 2018 to 2020 Predictions.",     xlab = "Year", ylab = "Sales (Million)") # Calculate the Mean Absolute Percentage Error mape <- mean(abs((actuals_preds$predicted - actuals_preds$actuals)) / actuals_preds$actuals) mape #K-Fold Cross validation library(DAAG) cvResults <- suppressWarnings(CVlm(data = sales_dataframe, form.lm = TotalSales ~ Year, m = 5, dots = FALSE, seed = 29, legend.pos = "topleft", printit = FALSE, main = "Small symbols are predicted values. Larger symbols are actuals.")) fit <- lm(Year ~ TotalSales, data = sales_dataframe) summary(fit)
